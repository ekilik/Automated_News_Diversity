{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import torch\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformers import set_seed, AdamW, AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('path_to_actors_training_data_created_in_step3', sep=';', quoting=csv.QUOTE_NONNUMERIC, encoding = 'utf-8') # csv\n",
    "# change article_id to integer\n",
    "df['article_id'] = df['article_id'].astype(int)\n",
    "# select only quoted actors\n",
    "df = df[df['quoted'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Buitenlandse Zaken:\\n Het ministerie van Buitenlandse Zaken zegt dat de ambassade in Peking de situatie op de voet volgt.',\n",
       "       'Wereldgezondheidsorganisatie:\\n Het ministerie adviseert reizigers de adviezen van het Landelijk Coordinatiecentrum Reizigersadvisering (LCR) en de Wereldgezondheidsorganisatie (WHO) in de gaten te houden. \\nDe Wereldgezondheidsorganisatie beschouwt de uitbraak van het virus als een Chinese aangelegenheid.',\n",
       "       'Bruins:\\n Minister Bruins voor Medische Zorg vindt het verschrikkelijk dat mensen met een Aziatisch uiterlijk worden gediscrimineerd vanwege het coronavirus. \\nBruins reageerde op vragen van onder anderen GroenLinks-Kamerlid Ellemeet. \\nBruins zei hierop dat hij dit de komende dagen nog verschillende keren wil doen, ook buiten de Tweede Kamer. \\nBruins is niet van plan om evenementen en attracties te sluiten die veel Chinese toeristen trekken, zoals de Keukenhof.',\n",
       "       'GroenLinks-Kamerlid Ellemeet:\\n Bruins reageerde op vragen van onder anderen GroenLinks-Kamerlid Ellemeet. \\nEllemeet vroeg de minister of hij zich hierover duidelijk wil uitspreken.',\n",
       "       'Aniek van Santvoort:\\n \"We kunnen de paarden niet naar China exporteren\", zegt eigenaar Aniek van Santvoort. \\n\"Wij hebben een hele brede groep klanten\", zegt Van Santvoort. \\nVan Santvoort heeft nog wel contact met kopers in China, maar nieuwe aanvragen blijven uit, vertelt ze: \\n\"Onze quarantainestal staat vol\", zegt Van Santvoort. \\n\"Nu komt er niks binnen\", zegt Van Santvoort. \\n\"Het gaat altijd over de grote bedrijven die importeren uit China, maar die hebben buffers waarmee ze dit soort problemen kunnen opvangen\", zegt Van Santvoort.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['input_text'].values[:5] # check input text created in step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the annotations df with researcher codings\n",
    "reliability_df = pd.read_csv('reliability_actors_final_cleaned_elif.csv',\n",
    "                             sep = ';', encoding = 'utf-8', quoting=csv.QUOTE_NONNUMERIC)\n",
    "\n",
    "reliability_df['article_id'] = reliability_df['article_id'].astype(int)\n",
    "reliability_df = reliability_df[reliability_df['coder'] == 'Elif Kilik']\n",
    "train_df = df[~df['article_id'].isin(reliability_df['article_id'])]\n",
    "test_df = df[df['article_id'].isin(reliability_df['article_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "talks_covid_measures\n",
       "0.0    752\n",
       "1.0    477\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.talks_covid_measures.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "talks_covid_measures\n",
       "0.0    138\n",
       "1.0    102\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.talks_covid_measures.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(983, 1) (246, 1)\n",
      "(983, 1) (246, 1)\n"
     ]
    }
   ],
   "source": [
    "X = train_df[['input_text']]\n",
    "y = train_df[['talks_covid_measures']]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=42, stratify=y)\n",
    "\n",
    "print(X_train.shape, X_val.shape)  # Shapes of the input texts\n",
    "print(y_train.shape, y_val.shape)    # Shapes of the binary labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tune RobBERT Dutch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "talks_covid_measures\n",
       "0.0    601\n",
       "1.0    382\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the nr of 1 labels in y_train and y_val\n",
    "y_train.talks_covid_measures.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "talks_covid_measures\n",
       "0.0    151\n",
       "1.0     95\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.talks_covid_measures.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to save the best model\n",
    "save_directory = \"path_to_save_best_model\"  # Replace with your desired path\n",
    "# Create the directory if it does not exist\n",
    "os.makedirs(save_directory, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# Hyperparameters\n",
    "learning_rates = [1e-5, 2e-5, 5e-5]\n",
    "accumulation_steps = 2  # This simulates a batch size of 16 by accumulating over 2 steps with batch size 8\n",
    "best_val_loss = float('inf')\n",
    "best_model_state = None\n",
    "patience = 3  # Number of epochs to wait before stopping if no improvement\n",
    "epochs_to_test = [3, 5]  # Epochs to test\n",
    "\n",
    "# Initialize tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"DTAI-KULeuven/robbert-2023-dutch-base\")\n",
    "\n",
    "# Encode data\n",
    "def encode(docs):\n",
    "    encoded_dict = tokenizer.batch_encode_plus(docs, add_special_tokens=True, padding='max_length',\n",
    "                                                return_attention_mask=True, truncation=True, return_tensors='pt')\n",
    "    return encoded_dict['input_ids'], encoded_dict['attention_mask']\n",
    "\n",
    "train_input_ids, train_att_masks = encode(X_train['input_text'].tolist())\n",
    "valid_input_ids, valid_att_masks = encode(X_val['input_text'].tolist())\n",
    "train_y = torch.LongTensor(y_train.values.squeeze())\n",
    "valid_y = torch.LongTensor(y_val.values.squeeze())\n",
    "\n",
    "train_dataset = TensorDataset(train_input_ids, train_att_masks, train_y)\n",
    "train_sampler = RandomSampler(train_dataset)\n",
    "train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=8)  \n",
    "\n",
    "valid_dataset = TensorDataset(valid_input_ids, valid_att_masks, valid_y)\n",
    "valid_sampler = SequentialSampler(valid_dataset)\n",
    "valid_dataloader = DataLoader(valid_dataset, sampler=valid_sampler, batch_size=8)\n",
    "\n",
    "# Loop through specified learning rates\n",
    "for learning_rate in learning_rates:\n",
    "    print(f\"\\nTraining with learning rate: {learning_rate}\")\n",
    "    \n",
    "    # Initialize the model for each learning rate\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\"DTAI-KULeuven/robbert-2023-dutch-base\", num_labels=2)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Define optimizer\n",
    "    optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    # Loop through specified epochs\n",
    "    for epochs in epochs_to_test:\n",
    "        print(f\"\\nTraining for {epochs} epochs...\")\n",
    "        patience_counter = 0  # To track epochs without improvement\n",
    "\n",
    "        for epoch_num in range(epochs):\n",
    "            print(f\"Epoch: {epoch_num + 1}/{epochs}\")\n",
    "\n",
    "            # Training\n",
    "            model.train()\n",
    "            train_loss = 0\n",
    "            for step_num, batch_data in enumerate(tqdm(train_dataloader, desc='Training')):\n",
    "                input_ids, att_mask, labels = [data.to(device) for data in batch_data]\n",
    "                output = model(input_ids=input_ids, attention_mask=att_mask, labels=labels)\n",
    "\n",
    "                loss = output.loss\n",
    "                train_loss += loss.item()\n",
    "\n",
    "                loss = loss / accumulation_steps  # Scale the loss\n",
    "                loss.backward()  # Backpropagate the loss\n",
    "\n",
    "                # Gradient accumulation\n",
    "                if (step_num + 1) % accumulation_steps == 0:\n",
    "                    clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "            # Average training loss for this epoch\n",
    "            train_loss /= len(train_dataloader)\n",
    "            print(f\"Train loss: {train_loss:.4f}\")\n",
    "\n",
    "            # Validation\n",
    "            model.eval()\n",
    "            valid_loss = 0\n",
    "            valid_pred = []\n",
    "            with torch.no_grad():\n",
    "                for step_num_e, batch_data in enumerate(tqdm(valid_dataloader, desc='Validation')):\n",
    "                    input_ids, att_mask, labels = [data.to(device) for data in batch_data]\n",
    "                    output = model(input_ids=input_ids, attention_mask=att_mask, labels=labels)\n",
    "                    loss = output.loss\n",
    "                    valid_loss += loss.item()\n",
    "                    valid_pred.append(output.logits.cpu().detach().numpy())\n",
    "\n",
    "            # Average validation loss for this epoch\n",
    "            valid_loss /= len(valid_dataloader)\n",
    "            print(f\"Validation loss: {valid_loss:.4f}\")\n",
    "\n",
    "            # Early stopping check\n",
    "            if valid_loss < best_val_loss:\n",
    "                best_val_loss = valid_loss\n",
    "                best_model_state = model.state_dict()\n",
    "                patience_counter = 0  # Reset patience counter if we have improvement\n",
    "                print(\"New best model found! Saving...\")\n",
    "                torch.save(best_model_state, os.path.join(save_directory, \"best_model_state.bin\"))\n",
    "                tokenizer.save_pretrained(save_directory)\n",
    "                model.config.save_pretrained(save_directory)\n",
    "                torch.save(optimizer.state_dict(), os.path.join(save_directory, \"optimizer_state.bin\"))\n",
    "                print(\"Model and optimizer states saved.\")\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                if patience_counter >= patience:\n",
    "                    print(\"Early stopping triggered.\")\n",
    "                    break  # Stop training if no improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 31/31 [00:01<00:00, 16.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.6006\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.89      0.90       151\n",
      "           1       0.83      0.84      0.84        95\n",
      "\n",
      "    accuracy                           0.87       246\n",
      "   macro avg       0.87      0.87      0.87       246\n",
      "weighted avg       0.87      0.87      0.87       246\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Validation\n",
    "model.eval()\n",
    "valid_loss = 0\n",
    "valid_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for step_num_e, batch_data in enumerate(tqdm(valid_dataloader, desc='Validation')):\n",
    "        input_ids, att_mask, labels = [data.to(device) for data in batch_data]\n",
    "        \n",
    "        # During validation, no need to pass labels to the model\n",
    "        output = model(input_ids=input_ids, attention_mask=att_mask)\n",
    "        logits = output.logits\n",
    "        \n",
    "        # Compute validation loss manually (if needed)\n",
    "        # loss = criterion(logits, labels)\n",
    "        valid_loss += loss.item()\n",
    "\n",
    "        # Store the logits for all validation examples\n",
    "        valid_pred.append(logits.cpu().detach().numpy())\n",
    "\n",
    "# Average validation loss\n",
    "valid_loss /= len(valid_dataloader)\n",
    "print(f\"Validation loss: {valid_loss:.4f}\")\n",
    "\n",
    "# Check if valid_pred has any entries before concatenation\n",
    "if valid_pred:\n",
    "    valid_pred = np.concatenate(valid_pred)  # Concatenate predictions from batches\n",
    "\n",
    "    # Apply softmax to get class probabilities\n",
    "    valid_pred_softmax = torch.softmax(torch.tensor(valid_pred), dim=1).numpy()\n",
    "\n",
    "    # Get the class predictions (0 or 1) based on the higher probability\n",
    "    valid_pred_labels = np.argmax(valid_pred_softmax, axis=1)\n",
    "\n",
    "    # Flatten ground truth for classification report\n",
    "    y_true = valid_y.numpy()\n",
    "\n",
    "    print(classification_report(y_true, valid_pred_labels, \n",
    "                                zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>135</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>15</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0   1\n",
       "True              \n",
       "0.0        135  16\n",
       "1.0         15  80"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(y_val['talks_covid_measures'], valid_pred_labels, rownames=['True'], colnames=['Predicted'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('path_to_test_data_researcher_codings',\n",
    "                 sep = ';', encoding = 'utf-8', quoting=csv.QUOTE_NONNUMERIC) #csv file\n",
    "\n",
    "# change article_id to integer\n",
    "test_df['article_id'] = test_df['article_id'].astype(int)\n",
    "# drop if colnames has unnamed \n",
    "test_df = test_df.loc[:, ~test_df.columns.str.contains('^Unnamed')]\n",
    "# keep only if directly_quoted or indirectly_quoted is 1\n",
    "test_df = test_df[(test_df['directly_quoted'] == 1) | (test_df['indirectly_quoted'] == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get article_id, actor_name, talks_covid_measures, relevant_sentences_string\n",
    "test_df = test_df[['article_id', 'actor_name', 'talks_covid_measures', 'input_text_corrected',\n",
    "       'talks_covid_corrected', 'measures_positive_corrected',\n",
    "       'measures_negative_corrected', 'measures_neutral_corrected']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "talks_covid_corrected\n",
       "0.0    181\n",
       "1.0    114\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.talks_covid_corrected.value_counts() # these are manually corrected labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 37/37 [00:02<00:00, 17.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.5945\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.92      0.90       181\n",
      "           1       0.86      0.82      0.84       114\n",
      "\n",
      "    accuracy                           0.88       295\n",
      "   macro avg       0.87      0.87      0.87       295\n",
      "weighted avg       0.88      0.88      0.88       295\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# encode input text for the test set\n",
    "test_input_ids, test_att_masks = encode(test_df['input_text_corrected'].tolist())\n",
    "test_y = torch.LongTensor(test_df['talks_covid_corrected'].values.squeeze())\n",
    "\n",
    "test_dataset = TensorDataset(test_input_ids, test_att_masks, test_y)\n",
    "test_sampler = SequentialSampler(test_dataset)\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=8)\n",
    "\n",
    "# the model is loaded\n",
    "\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "\n",
    "test_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for step_num_e, batch_data in enumerate(tqdm(test_dataloader, desc='Testing')):\n",
    "        input_ids, att_mask, labels = [data.to(device) for data in batch_data]\n",
    "        output = model(input_ids=input_ids, attention_mask=att_mask, labels=labels)\n",
    "        loss = output.loss\n",
    "        test_loss += loss.item()\n",
    "        test_pred.append(output.logits.cpu().detach().numpy())\n",
    "\n",
    "# Average test loss\n",
    "test_loss /= len(test_dataloader)\n",
    "print(f\"Test loss: {test_loss:.4f}\")\n",
    "\n",
    "# Check if test_pred has any entries before concatenation\n",
    "\n",
    "if test_pred:\n",
    "    test_pred = np.concatenate(test_pred)  # Concatenate predictions from batches\n",
    "\n",
    "    # Apply softmax to get class probabilities\n",
    "    test_pred_softmax = torch.softmax(torch.tensor(test_pred), dim=1).numpy()\n",
    "\n",
    "    # Get the class predictions\n",
    "    test_pred_labels = np.argmax(test_pred_softmax, axis=1)\n",
    "\n",
    "    # Flatten ground truth for classification report\n",
    "    y_true = test_y.numpy()\n",
    "\n",
    "print(classification_report(y_true, test_pred_labels, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append the predictions to the talks_covid_corrected\n",
    "test_df['talks_covid_pred_robbert'] = test_pred_labels\n",
    "\n",
    "# save the test_df with predictions\n",
    "test_df.to_csv('path_to_save_test_df_with_predictions/actors_discusses_measures_RobBERTpreds.csv', sep=';', index=False, quoting=csv.QUOTE_NONNUMERIC, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
