{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import nltk\n",
    "import spacy\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('path_to_actors_training_data_created_in_step3', sep=';', quoting=csv.QUOTE_NONNUMERIC, encoding = 'utf-8') # csv\n",
    "# change article_id to integer\n",
    "df['article_id'] = df['article_id'].astype(int)\n",
    "# select only quoted actors\n",
    "df = df[df['quoted'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the annotations df with researcher codings\n",
    "reliability_df = pd.read_csv('reliability_actors_final_cleaned_elif.csv',\n",
    "                             sep = ';', encoding = 'utf-8', quoting=csv.QUOTE_NONNUMERIC)\n",
    "\n",
    "reliability_df['article_id'] = reliability_df['article_id'].astype(int)\n",
    "reliability_df = reliability_df[reliability_df['coder'] == 'Elif Kilik']\n",
    "train_df = df[~df['article_id'].isin(reliability_df['article_id'])]\n",
    "test_df = df[df['article_id'].isin(reliability_df['article_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1229, 13)\n"
     ]
    }
   ],
   "source": [
    "# limit df only to article_ids that are not in the test_df\n",
    "train_df = df[~df['article_id'].isin(reliability_df['article_id'])]\n",
    "print(train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 13)\n"
     ]
    }
   ],
   "source": [
    "test_df = df[df['article_id'].isin(reliability_df['article_id'])]\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "talks_covid_measures\n",
       "0.0    752\n",
       "1.0    477\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.talks_covid_measures.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(477, 13)\n"
     ]
    }
   ],
   "source": [
    "# keep only if talks_covid_measures is 1\n",
    "train_df = train_df[train_df['talks_covid_measures'] == 1]\n",
    "print(train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bruins:\\n Minister Bruins voor Medische Zorg vindt het verschrikkelijk dat mensen met een Aziatisch uiterlijk worden gediscrimineerd vanwege het coronavirus. \\nBruins reageerde op vragen van onder anderen GroenLinks-Kamerlid Ellemeet. \\nBruins zei hierop dat hij dit de komende dagen nog verschillende keren wil doen, ook buiten de Tweede Kamer. \\nBruins is niet van plan om evenementen en attracties te sluiten die veel Chinese toeristen trekken, zoals de Keukenhof.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.input_text.values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a text preprocessing function where you lowercase the text and then lemmitize the text\n",
    "def text_lower(text):\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "train_df['input_text_lower'] = train_df['input_text'].apply(text_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bruins:\n",
      " Minister Bruins voor Medische Zorg vindt het verschrikkelijk dat mensen met een Aziatisch uiterlijk worden gediscrimineerd vanwege het coronavirus. \n",
      "Bruins reageerde op vragen van onder anderen GroenLinks-Kamerlid Ellemeet. \n",
      "Bruins zei hierop dat hij dit de komende dagen nog verschillende keren wil doen, ook buiten de Tweede Kamer. \n",
      "Bruins is niet van plan om evenementen en attracties te sluiten die veel Chinese toeristen trekken, zoals de Keukenhof.\n",
      "bruins:\n",
      " minister bruins voor medische zorg vindt het verschrikkelijk dat mensen met een aziatisch uiterlijk worden gediscrimineerd vanwege het coronavirus. \n",
      "bruins reageerde op vragen van onder anderen groenlinks-kamerlid ellemeet. \n",
      "bruins zei hierop dat hij dit de komende dagen nog verschillende keren wil doen, ook buiten de tweede kamer. \n",
      "bruins is niet van plan om evenementen en attracties te sluiten die veel chinese toeristen trekken, zoals de keukenhof.\n"
     ]
    }
   ],
   "source": [
    "print(train_df['input_text'].values[0])\n",
    "print(train_df['input_text_lower'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "measures_positive\n",
       "0.0    309\n",
       "1.0    168\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.measures_positive.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tf-IDF + SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (381, 1)\n",
      "y_train shape: (381,)\n"
     ]
    }
   ],
   "source": [
    "# Select your features and target variable\n",
    "X = train_df[['input_text_lower']]  # This should remain a DataFrame\n",
    "y = train_df['measures_positive'].values.flatten()  # Convert to 1D array\n",
    "\n",
    "# Split the data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")  # Should be (n_samples_train, n_features)\n",
    "print(f\"y_train shape: {y_train.shape}\")  # Should be (n_samples_train,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_val shape: (96, 1)\n",
      "y_val shape: (96,)\n"
     ]
    }
   ],
   "source": [
    "# shape of the validation set\n",
    "print(f\"X_val shape: {X_val.shape}\")  # Should be (n_samples_val, n_features)\n",
    "print(f\"y_val shape: {y_val.shape}\")  # Should be (n_samples_val,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nr of 1 labels in y_train: 134.0\n",
      "Nr of 1 labels in y_val: 34.0\n"
     ]
    }
   ],
   "source": [
    "# get the nr of 1 labels in y_train and y_val\n",
    "print(f\"Nr of 1 labels in y_train: {sum(y_train)}\")\n",
    "print(f\"Nr of 1 labels in y_val: {sum(y_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\elifk\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stopwords = nltk.corpus.stopwords.words('dutch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid\n",
    "param_grid_svc = {\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'tfidf__max_features': [100, 2000, 1000, 5000, 10000],\n",
    "    'clf__C': [0.1, 1, 10, 50, 100],\n",
    "    'clf__max_iter': [100, 500, 1000]\n",
    "}\n",
    "\n",
    "# Define the SVC pipeline\n",
    "pipeline_svc = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(1, 1), analyzer='word', stop_words=stopwords)),\n",
    "    ('clf', LinearSVC(random_state=0))\n",
    "])\n",
    "\n",
    "# Perform grid search for SVC\n",
    "grid_search_svc = GridSearchCV(pipeline_svc, param_grid_svc, cv=5, scoring='f1_macro')\n",
    "grid_search_svc.fit(X_train['input_text_lower'], y_train)  # Use the column name directly\n",
    "\n",
    "print(f\"Best parameters for SVC: {grid_search_svc.best_params_}\")\n",
    "print(f\"Best score for SVC: {grid_search_svc.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found for SVC:  {'clf__C': 1, 'clf__max_iter': 100, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 2)}\n",
      "Best model found for SVC:  Pipeline(steps=[('tfidf',\n",
      "                 TfidfVectorizer(max_features=5000, ngram_range=(1, 2),\n",
      "                                 stop_words=['de', 'en', 'van', 'ik', 'te',\n",
      "                                             'dat', 'die', 'in', 'een', 'hij',\n",
      "                                             'het', 'niet', 'zijn', 'is', 'was',\n",
      "                                             'op', 'aan', 'met', 'als', 'voor',\n",
      "                                             'had', 'er', 'maar', 'om', 'hem',\n",
      "                                             'dan', 'zou', 'of', 'wat', 'mijn', ...])),\n",
      "                ('clf', LinearSVC(C=1, max_iter=100, random_state=0))])\n"
     ]
    }
   ],
   "source": [
    "# Get the best parameters and the best model\n",
    "best_params = grid_search_svc.best_params_\n",
    "best_model = grid_search_svc.best_estimator_\n",
    "\n",
    "print(\"Best parameters found for SVC: \", best_params)\n",
    "print(\"Best model found for SVC: \", best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the predictions for the validation set\n",
    "val_preds = best_model.predict(X_val['input_text_lower'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_labels = y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>54</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>18</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  0.0  1.0\n",
       "Actual             \n",
       "0.0         54    8\n",
       "1.0         18   16"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(val_labels, val_preds, rownames=['Actual'], colnames=['Predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.75      0.81        72\n",
      "         1.0       0.47      0.67      0.55        24\n",
      "\n",
      "    accuracy                           0.73        96\n",
      "   macro avg       0.67      0.71      0.68        96\n",
      "weighted avg       0.77      0.73      0.74        96\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('classification report')\n",
    "print(classification_report(val_preds, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('path_to_test_data_researcher_codings',\n",
    "                 sep = ';', encoding = 'utf-8', quoting=csv.QUOTE_NONNUMERIC) #csv file\n",
    "\n",
    "# change article_id to integer\n",
    "test_df['article_id'] = test_df['article_id'].astype(int)\n",
    "# drop if colnames has unnamed \n",
    "test_df = test_df.loc[:, ~test_df.columns.str.contains('^Unnamed')]\n",
    "# keep only if directly_quoted or indirectly_quoted is 1\n",
    "test_df = test_df[(test_df['directly_quoted'] == 1) | (test_df['indirectly_quoted'] == 1)]\n",
    "# keep only if talks_covid_measures is 1\n",
    "test_df = test_df[test_df['talks_covid_corrected'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(114, 8)\n"
     ]
    }
   ],
   "source": [
    "# get article_id, actor_name, talks_covid_measures, relevant_sentences_string\n",
    "test_df = test_df[['article_id', 'actor_name', 'talks_covid_measures', 'input_text_corrected',\n",
    "       'talks_covid_corrected', 'measures_positive_corrected',\n",
    "       'measures_negative_corrected', 'measures_neutral_corrected']]\n",
    "\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make column input_text\n",
    "test_df['input_text_lower'] = test_df['input_text_corrected'].apply(text_lower)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds_elif = best_model.predict(test_df['input_text_lower'])\n",
    "\n",
    "test_labels_elif = test_df['measures_positive_corrected'].values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>24</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  0.0  1.0\n",
       "Actual             \n",
       "0.0         64   10\n",
       "1.0         24   16"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# crosstab\n",
    "pd.crosstab(test_labels_elif, test_preds_elif, rownames=['Actual'], colnames=['Predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.73      0.79        88\n",
      "         1.0       0.40      0.62      0.48        26\n",
      "\n",
      "    accuracy                           0.70       114\n",
      "   macro avg       0.63      0.67      0.64       114\n",
      "weighted avg       0.76      0.70      0.72       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('classification report')\n",
    "print(classification_report(test_preds_elif, test_labels_elif))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put the predictions in the df\n",
    "test_df['covid_measures_positive_pred_SVM'] = test_preds_elif\n",
    "\n",
    "test_df.to_csv('path_to_save_test_df_with_predictions/actor_positive_stance_preds_SVM.csv',\n",
    "               sep = ';', encoding = 'utf-8', index = False, quoting=csv.QUOTE_NONNUMERIC)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
