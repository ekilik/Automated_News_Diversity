{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Packages & Set Working Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import re\n",
    "import pandas as pd\n",
    "import transformers\n",
    "import torch\n",
    "\n",
    "from torch import cuda, bfloat16\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "\n",
    "from sklearn.metrics import classification_report, cohen_kappa_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()\n",
    "\n",
    "# go one level up in the directory\n",
    "os.chdir(\"/data/500gbstorage/\")\n",
    "\n",
    "huggingface_cache_dir = 'model_mistral'\n",
    "\n",
    "# change huggingface cache\n",
    "os.environ['TRANSFORMERS_CACHE'] = huggingface_cache_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Model from Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading shards: 100%|██████████| 3/3 [00:00<00:00,  9.12it/s]\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [10:27<00:00, 209.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded on cuda:0\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "model_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "device = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'\n",
    "# set model access token for huggingface\n",
    "hf_token = 'hf_XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX'\n",
    "\n",
    "print(device)\n",
    "\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=bfloat16,\n",
    "    device_map='auto',\n",
    "    token=hf_token,\n",
    "    cache_dir=huggingface_cache_dir)\n",
    "model.eval()\n",
    "\n",
    "torch.manual_seed(0)\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model_id, token=hf_token, cache_dir=huggingface_cache_dir)\n",
    "\n",
    "print(f\"Model loaded on {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Name: NVIDIA A100 80GB PCIe\n",
      "Memory Usage: 13.488792419433594 GB\n",
      "Max Memory Usage: 13.488792419433594 GB\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "print(\"GPU Name:\", torch.cuda.get_device_name(device))\n",
    "print(\"Memory Usage:\", torch.cuda.memory_allocated(device) / 1024 ** 3, \"GB\")\n",
    "print(\"Max Memory Usage:\", torch.cuda.max_memory_allocated(device) / 1024 ** 3, \"GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "generate_text = transformers.pipeline(\n",
    "    model=model, tokenizer=tokenizer,\n",
    "    task='text-generation',\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    "    temperature=0,  # 'randomness' of outputs, 0.0 is not possible, so use a very small number\n",
    "    max_new_tokens=512,  # max number of tokens to generate in the output\n",
    "    repetition_penalty=1.1  \n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=generate_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regex_extract_to_dataframe(strings):\n",
    "    # Initialize empty lists to store extracted values\n",
    "    article_ids = []\n",
    "    about_covid_values = []\n",
    "\n",
    "    # Define regex pattern for article_id and about_covid with optional double quotes\n",
    "    article_id_pattern = r'\"article_id\"\\s*:\\s*\"?(\\d+)\"?'\n",
    "    about_covid_pattern = r'\"about_covid\"\\s*:\\s*\"?(\\d)\"?'\n",
    "\n",
    "    # Iterate through each string\n",
    "    for string_data in strings:\n",
    "        # replace \\ with nothing\n",
    "        string_data = string_data.replace(\"\\\\\", \"\")\n",
    "        \n",
    "        # Use regex to find matches for article_id\n",
    "        article_id_match = re.search(article_id_pattern, string_data)\n",
    "\n",
    "        # Use regex to find matches for about_covid\n",
    "        about_covid_match = re.search(about_covid_pattern, string_data)\n",
    "\n",
    "        # Extract values from the regex matches\n",
    "        article_id = int(article_id_match.group(1)) if article_id_match else None\n",
    "        about_covid = int(about_covid_match.group(1)) if about_covid_match else None\n",
    "\n",
    "        # Append values to the respective lists\n",
    "        article_ids.append(article_id)\n",
    "        about_covid_values.append(about_covid)\n",
    "\n",
    "    # Create a DataFrame using the extracted values\n",
    "    df = pd.DataFrame({\n",
    "        \"article_id\": article_ids,\n",
    "        \"about_covid\": about_covid_values\n",
    "    })\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_shot_prompt_messages(prompt_text):\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": prompt_text}\n",
    "    ]\n",
    "    prompt = generate_text.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the NOS articles annotated by the researcher\n",
    "df = pd.read_csv('NOS/nos_analysis/topic_tests_reliability_data/reliability_topics_elif.csv',\n",
    "                 sep = ';', encoding = 'utf-8', quoting=csv.QUOTE_NONNUMERIC)\n",
    "\n",
    "# change article_id to integer\n",
    "df['article_id'] = df['article_id'].astype(int)\n",
    "\n",
    "topic_vars = ['about_covid',  'topic_a', 'topic_b', 'topic_c', 'topic_d', 'topic_e', 'topic_f', 'topic_g', 'topic_h', \n",
    "              'topic_i', 'topic_j', 'topic_k', 'topic_l', 'topic_m', 'topic_n']\n",
    "\n",
    "# change all topic vars to int\n",
    "for i in topic_vars:\n",
    "    df[i] = df[i].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# articles df including text, category, keywords \n",
    "articles_df = pd.read_csv('NOS/nos_analysis/data/final_nosarticles.csv',\n",
    "                          sep = ';', encoding = 'utf-8', quoting=csv.QUOTE_NONNUMERIC)\n",
    "print(articles_df.shape)\n",
    "\n",
    "# get article text, category, keywords and page_id\n",
    "articles_df = articles_df[['page_id', 'Text', 'Category', 'Keywords']].drop_duplicates()\n",
    "# make page id integer\n",
    "articles_df['page_id'] = articles_df['page_id'].astype(int)\n",
    "# change page_id to article_id\n",
    "articles_df.rename(columns = {'page_id': 'article_id'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge articles_df with df\n",
    "df = pd.merge(df, articles_df, on='article_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 4)\n"
     ]
    }
   ],
   "source": [
    "# unique articles from researcher annotations\n",
    "unique_articles = df[['article_id', 'Keywords', 'Category', 'Text']].drop_duplicates()\n",
    "print(unique_articles.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_text = \"\"\"\n",
    "As a helpful AI assistant, your task is to determine the main topic of news articles. Articles may focus on either the \"Coronavirus and/or the COVID-19 pandemic\" or some other topic.\n",
    "A main topic is the overarching theme discussed in the majority of the news article. For an article to have the main topic of the \"Coronavirus and/or the COVID-19 pandemic\", it should predominantly discuss these subjects.\n",
    "\n",
    "Read the following article with the ID {article_id}: <<< {text} >>>\n",
    "\n",
    "This article falls under the categories: {category} and contains the keywords: {keywords}. \n",
    "\n",
    "Take a moment to understand the article. \n",
    "Remember, for a topic to be a main topic of the news article, it should be discussed in the majority of the article. \n",
    "\n",
    "Based on the information provided, determine if the main topic of this news article is the \"Coronavirus and/or the COVID-19 pandemic\" or another subject. \n",
    "Assign a value of 1 if the main topic is the \"Coronavirus and/or the COVID-19 pandemic\", and a value of 0 if the main topic is another subject.\n",
    "\n",
    "Your response should be in the following JSON format, without any additional explanations or notes:\n",
    "\n",
    "{{\n",
    "    \"article_id\": \"2000000\",\n",
    "    \"about_covid\": \"1\"\n",
    "}}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotating Articles About Covid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> [INST] \n",
      "As a helpful AI assistant, your task is to determine the main topic of news articles. Articles may focus on either the \"Coronavirus and/or the COVID-19 pandemic\" or some other topic.\n",
      "A main topic is the overarching theme discussed in the majority of the news article. For an article to have the main topic of the \"Coronavirus and/or the COVID-19 pandemic\", it should predominantly discuss these subjects.\n",
      "\n",
      "Read the following article with the ID {article_id}: <<< {text} >>>\n",
      "\n",
      "This article falls under the categories: {category} and contains the keywords: {keywords}. \n",
      "\n",
      "Take a moment to understand the article. \n",
      "Remember, for a topic to be a main topic of the news article, it should be discussed in the majority of the article. \n",
      "\n",
      "Based on the information provided, determine if the main topic of this news article is the \"Coronavirus and/or the COVID-19 pandemic\" or another subject. \n",
      "Assign a value of 1 if the main topic is the \"Coronavirus and/or the COVID-19 pandemic\", and a value of 0 if the main topic is another subject.\n",
      "\n",
      "Your response should be in the following JSON format, without any additional explanations or notes:\n",
      "\n",
      "{{\n",
      "    \"article_id\": \"2000000\",\n",
      "    \"about_covid\": \"1\"\n",
      "}}\n",
      " [/INST]\n"
     ]
    }
   ],
   "source": [
    "zero_shot_prompt = zero_shot_prompt_messages(prompt_text)\n",
    "print(zero_shot_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"article_id\", \"text\", \"category\", \"keywords\"],\n",
    "    template=zero_shot_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMChain(prompt=PromptTemplate(input_variables=['article_id', 'category', 'keywords', 'text'], template='<s> [INST] \\nAs a helpful AI assistant, your task is to determine the main topic of news articles. Articles may focus on either the \"Coronavirus and/or the COVID-19 pandemic\" or some other topic.\\nA main topic is the overarching theme discussed in the majority of the news article. For an article to have the main topic of the \"Coronavirus and/or the COVID-19 pandemic\", it should predominantly discuss these subjects.\\n\\nRead the following article with the ID {article_id}: <<< {text} >>>\\n\\nThis article falls under the categories: {category} and contains the keywords: {keywords}. \\n\\nTake a moment to understand the article. \\nRemember, for a topic to be a main topic of the news article, it should be discussed in the majority of the article. \\n\\nBased on the information provided, determine if the main topic of this news article is the \"Coronavirus and/or the COVID-19 pandemic\" or another subject. \\nAssign a value of 1 if the main topic is the \"Coronavirus and/or the COVID-19 pandemic\", and a value of 0 if the main topic is another subject.\\n\\nYour response should be in the following JSON format, without any additional explanations or notes:\\n\\n{{\\n    \"article_id\": \"2000000\",\\n    \"about_covid\": \"1\"\\n}}\\n [/INST]'), llm=HuggingFacePipeline(pipeline=<transformers.pipelines.text_generation.TextGenerationPipeline object at 0x7a7621d562b0>), output_key='article_id, about_covid')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_one = LLMChain(llm = llm, prompt = prompt_template, output_key=\"article_id, about_covid\")\n",
    "chain_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_text_zeroshot = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "torch.manual_seed(0)\n",
    "\n",
    "for index, row in unique_articles.iterrows():  \n",
    "    article_id = row['article_id']\n",
    "    text = row['Text']\n",
    "    category = row['Category']\n",
    "    keywords = row['Keywords']\n",
    "\n",
    "\n",
    "    input_variables = {\n",
    "            \"article_id\": article_id,\n",
    "            \"text\": text,\n",
    "            \"category\": category,\n",
    "            \"keywords\": keywords\n",
    "        }\n",
    "    # Generate text using the chain\n",
    "    generated_text = chain_one.run(input_variables)\n",
    "    print(generated_text)\n",
    "    generated_text_zeroshot.append(generated_text)    \n",
    "\n",
    "# CPU times: user 2min 3s, sys: 748 ms, total: 2min 4s\n",
    "# Wall time: 2min 13s\n",
    "# output cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_list = regex_extract_to_dataframe(generated_text_zeroshot)\n",
    "df_zeroshot = pd.DataFrame(json_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>about_covid_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2322751</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2325123</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2326923</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2328119</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2328418</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id  about_covid_pred\n",
       "0     2322751                 1\n",
       "1     2325123                 1\n",
       "2     2326923                 1\n",
       "3     2328119                 1\n",
       "4     2328418                 1"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rename about_covid to about_covid_pred\n",
    "df_zeroshot = df_zeroshot.rename(columns={'about_covid': 'about_covid_pred'})\n",
    "df_zeroshot['article_id'] = df_zeroshot['article_id'].astype(int)\n",
    "df_zeroshot['about_covid_pred'] = df_zeroshot['about_covid_pred'].astype(int)\n",
    "\n",
    "df_zeroshot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_elif = df[df['coder'] == 'Elif Kilik']\n",
    "df_coded_elif = df_elif[['article_id', 'about_covid']]\n",
    "df_zeroshot_merged_elif = pd.merge(df_coded_elif, df_zeroshot, how='left', on=\"article_id\")\n",
    "print(len(df_zeroshot_merged_elif))\n",
    "\n",
    "df_zeroshot_merged_elif = df_zeroshot_merged_elif.dropna()\n",
    "df_zeroshot_merged_elif['about_covid_pred'] = df_zeroshot_merged_elif['about_covid_pred'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95        42\n",
      "           1       0.97      0.97      0.97        78\n",
      "\n",
      "    accuracy                           0.97       120\n",
      "   macro avg       0.96      0.96      0.96       120\n",
      "weighted avg       0.97      0.97      0.97       120\n",
      "\n",
      "Cohen's Kappa: 0.9267399267399268\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df_zeroshot_merged_elif['about_covid'], df_zeroshot_merged_elif['about_covid_pred']))\n",
    "print(\"Cohen's Kappa:\", cohen_kappa_score(df_zeroshot_merged_elif['about_covid'], df_zeroshot_merged_elif['about_covid_pred']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
